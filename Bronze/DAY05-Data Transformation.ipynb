{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95748c9c-2c67-462c-9a24-8a53c20927d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sourceFileUrl=\"/Volumes/workspace/default/lakehouse\"\n",
    "sourceJSONUrl=\"/Volumes/workspace/default/lakehouse/Json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32c5282d-496c-49e8-8736-1ecae07c5a83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Load JSON Data Without Schema\n",
    " _Read the source JSON file without specifying a schema_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4785a167-b30f-44bd-a054-6625e8724263",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sourceJsonfiledf=(spark.\n",
    " read.\n",
    " json(sourceJSONUrl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0335524f-a81d-447f-b406-5eee7097f135",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Define Schema for JSON Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8df209f9-e1c1-4094-91db-87013d59e082",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the schema for the source JSON file using DDL format\n",
    "sourceJsonfileSchenaDDL = (\n",
    "    \"ARRIVAL_IN_TONNES Decimal(10,2), DATE_OF_PRICING string, MARKET_NAME string, \"\n",
    "    \"MAXIMUM_PRICE string, MINIMUM_PRICE string, MODAL_PRICE string, ORIGIN string, \"\n",
    "    \"PRODUCTGROUP_NAME string, PRODUCT_NAME string, ROW_ID Integer, STATE_NAME string, VARIETY string\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfaa7f2b-7167-4b8a-978c-2e3815eea902",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Load JSON Data With Defined Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cd88685-6c87-4d0e-86ae-bcc6f59b0dd5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the source JSON file using the defined schema\n",
    "sourceJSONFileDf = (\n",
    "    spark.read.json(\n",
    "        sourceJSONUrl,\n",
    "        schema=sourceJsonfileSchenaDDL\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59558d43-1ca3-4a7a-8d87-bde782ce01d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sourceJSONFileDf.select(\"PRODUCT_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "961df469-8ca1-4743-89fd-c4be0b3d2114",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Drop the ROW_ID Column from DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0319aee-a683-4543-8f71-44b518bf01db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Remove the 'ROW_ID' column from sourceJSONFileDf and return a new DataFrame\n",
    "sourceJSONFileDf.drop(\"ROW_ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7acd2b2-efbf-404f-84cb-c8e0353cc680",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Filter and Sort Product Arrivals by State and Quantity\n",
    "\n",
    "The following cells demonstrate how to filter products with arrivals greater than 100 tonnes, restrict results to the state \"Andhra pradesh\", and sort the results by arrival quantity. Each cell builds on the previous by adding sorting or using different sorting functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3edd68a-2ab6-4a1f-9fb8-65b0c3527a3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Select products and arrival quantities, filter for arrivals > 100\n",
    "(sourceJSONFileDf.\n",
    "select(\"PRODUCT_NAME\",\"ARRIVAL_IN_TONNES\").\n",
    "filter(\"arrival_in_tonnes > 100\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb4c03db-89e0-4f16-861f-3c891ef0dc6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Select products and arrival quantities, filter for arrivals > 100, and restrict to \"Andhra pradesh\"\n",
    "from pyspark.sql.functions import col\n",
    "(sourceJSONFileDf.select(\"PRODUCT_NAME\",\"ARRIVAL_IN_TONNES\").\n",
    "filter(\"arrival_in_tonnes > 100\").where(col(\"STATE_NAME\")==\"Andhra Pradesh\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f82a8da1-5257-429a-9189-a443e5391c98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Same as above, but sorts results by \"ARRIVAL_IN_TONNES\" in ascending order\n",
    "(sourceJSONFileDf.select(\"PRODUCT_NAME\", \"ARRIVAL_IN_TONNES\")\n",
    " .filter(\"arrival_in_tonnes > 100\")\n",
    " .where(col(\"STATE_NAME\") == \"Andhra Pradesh\")\n",
    " .sort(\"ARRIVAL_IN_TONNES\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b28bc5c-47ce-4e56-97ee-c4c71f6cbad1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sorts results by \"ARRIVAL_IN_TONNES\" in descending order using desc()\n",
    "from pyspark.sql.functions import desc\n",
    "(sourceJSONFileDf.select(\"PRODUCT_NAME\", \"ARRIVAL_IN_TONNES\")\n",
    " .filter(\"arrival_in_tonnes > 100\")\n",
    " .where(col(\"STATE_NAME\") == \"Andhra Pradesh\")\n",
    " .sort(desc(\"ARRIVAL_IN_TONNES\")).show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b60077d3-fe5f-4e46-832c-d16c66129d6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display distinct state names from the DataFrame in sorted order\n",
    "# This code selects the 'STATE_NAME' column, removes duplicate state names,\n",
    "# sorts them alphabetically, and displays the result using Databricks' rich display.\n",
    "\n",
    "display(\n",
    "    sourceJSONFileDf\n",
    "        .select(\"STATE_NAME\")      # Select only the 'STATE_NAME' column\n",
    "        .distinct()                # Get unique state names\n",
    "        .sort(\"STATE_NAME\")        # Sort state names alphabetically\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2f7f8f7-e261-4cb1-8386-72c075959512",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display the total number of records in the DataFrame\n",
    "# This code counts the number of rows in 'sourceJSONFileDf' and displays the result using Databricks' rich display.\n",
    "display(sourceJSONFileDf.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6db4f209-85d0-4d82-b2b6-b48a5afc2407",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display the schema and contents of the DataFrame\n",
    "# This code prints the schema of 'sourceJSONFileDf', showing column names and data types,\n",
    "# and then displays the DataFrame using Databricks' rich display for easy exploration.\n",
    "\n",
    "sourceJSONFileDf.printSchema()  # Print the schema of the DataFrame\n",
    "display(sourceJSONFileDf)       # Display the DataFrame contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08f16785-5eef-4738-8f19-c5722447e1d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display the first row of the DataFrame\n",
    "# This code retrieves the first record from 'sourceJSONFileDf'.\n",
    "# Useful for quickly inspecting the structure and sample data of the DataFrame.\n",
    "\n",
    "(sourceJSONFileDf.\n",
    " first()\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b210b543-f98b-479b-a0da-8ab669fd5462",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display the first row of the DataFrame\n",
    "# This code retrieves the first record from 'sourceJSONFileDf' using the 'head()' method.\n",
    "# Useful for quickly inspecting the structure and sample data of the DataFrame.\n",
    "\n",
    "(sourceJSONFileDf.\n",
    " head()\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ebbf393-b44d-4a10-881c-6b6b5e351bdc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display the first 10 rows of the DataFrame\n",
    "# This code retrieves the first 10 records from 'sourceJSONFileDf' using the 'take(10)' method.\n",
    "# Useful for quickly inspecting a sample of the data in the DataFrame.\n",
    "\n",
    "display(\n",
    "    sourceJSONFileDf.take(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46e5ceb4-ef16-4be7-95a5-2c83052894cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display the contents of the DataFrame and format the 'ARRIVAL_IN_TONNES' column\n",
    "# This code first displays the full DataFrame using Databricks' rich display.\n",
    "# Then, it creates a new DataFrame with the 'ARRIVAL_IN_TONNES' column formatted to two decimal places,\n",
    "# renaming the column to indicate its decimal format, and displays the result.\n",
    "\n",
    "display(sourceJSONFileDf)  # Display the original DataFrame\n",
    "\n",
    "from pyspark.sql.functions import format_number\n",
    "\n",
    "display(\n",
    "    sourceJSONFileDf.withColumn(\n",
    "        \"ARRIVAL_IN_TONNES Decimal(10,2)\",  # New column name indicating decimal format\n",
    "        format_number(\"ARRIVAL_IN_TONNES\", 2)  # Format 'ARRIVAL_IN_TONNES' to two decimal places\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DAY05-Data Transformation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
